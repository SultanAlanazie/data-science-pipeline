# ğŸ›ï¸ Fashion Forward Forecasting - StyleSense Product Recommendation Pipeline

> **Build a machine learning pipeline to predict customer product recommendations using NLP and scikit-learn**

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE.txt)
[![Status](https://img.shields.io/badge/Status-Complete-success.svg)]()

---

## ğŸ“Œ Project Overview

This is a **complete machine learning project** demonstrating a production-ready pipeline for predicting product recommendations. The project handles mixed data types (numerical, categorical, text) and implements best practices including data preprocessing, feature engineering, model training, cross-validation, and hyperparameter tuning.

### ğŸ¯ Problem Statement

StyleSense, an online women's clothing retailer, receives thousands of customer reviews but not all include explicit recommendation indicators. This project automates recommendation prediction by analyzing review text, customer demographics, and product information.

### ğŸ“Š Dataset

- **18,442** customer reviews
- **8 features** (numerical, categorical, text)
- **81.6%** positive class distribution
- **9 columns** total (including target)

---

## ğŸš€ Quick Start

### âš¡ 5-Minute Setup

```bash
# Clone repository
git clone https://github.com/udacity/dsnd-pipelines-project.git
cd dsnd-pipelines-project

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm

# Start Jupyter
jupyter notebook
```

Then open **`starter/starter.ipynb`** and follow the cells!

---

## ğŸ“¦ Dependencies

### Core Libraries
```
scikit-learn>=1.0.0      # Machine Learning
pandas>=1.3.0            # Data Manipulation
numpy>=1.21.0            # Numerical Computing
spacy>=3.0.0             # NLP Processing
```

### Visualization & Jupyter
```
notebook>=6.4.0          # Jupyter Notebook
matplotlib>=3.4.0        # Plotting
seaborn>=0.11.0          # Statistical Plots
```

### Installation Methods

**Option 1: Using requirements.txt**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

**Option 2: Manual Installation**
```bash
pip install scikit-learn pandas numpy spacy notebook matplotlib seaborn
python -m spacy download en_core_web_sm
```

**For Mac M1/M2:**
```bash
pip install 'spacy[apple]'
python -m spacy download en_core_web_sm
```

---

## ğŸ“ Project Structure

```
dsnd-pipelines-project/
â”‚
â”œâ”€â”€ starter/                          # ğŸ“‚ Student-facing folder
â”‚   â”œâ”€â”€ README.md                     # âœï¸ Instructions for students
â”‚   â”œâ”€â”€ starter.ipynb                 # ğŸ““ Main notebook template
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ reviews.csv               # ğŸ“Š Dataset (18,442 reviews)
â”‚
â”œâ”€â”€ requirements.txt                  # ğŸ“ Project dependencies
â”œâ”€â”€ README.md                         # ğŸ“– This file
â”œâ”€â”€ LICENSE.txt                       # âš–ï¸ MIT License
â”œâ”€â”€ .gitignore                        # ğŸ”’ Git ignore rules
â””â”€â”€ CODEOWNERS                        # ğŸ‘¥ Project maintainers
```

### ğŸ“‚ Key Folders

| Folder | Purpose |
|--------|---------|
| **`starter/`** | Scaffolded project files for students |
| **`starter/data/`** | Customer review CSV dataset |

---

## ğŸ“‹ Project Instructions

### Part 1ï¸âƒ£: Data Exploration

Understand the dataset by examining:
- Data types and distributions
- Missing values
- Feature statistics
- Text data characteristics
- Class balance

### Part 2ï¸âƒ£: Feature Engineering

Create new features from raw data:
- **Text Features**: Review length, word count, sentiment indicators
- **Numerical Features**: Already provided (age, feedback count)
- **Categorical Features**: Product divisions, departments, classes

### Part 3ï¸âƒ£: Build Pipeline

Construct a complete ML pipeline:

```python
Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(), categorical_features),
        ('text', TfidfVectorizer(), text_features)
    ])),
    ('classifier', RandomForestClassifier(n_estimators=100))
])
```

### Part 4ï¸âƒ£: Train Model

- Train on 16,597 samples (90%)
- Evaluate on training set
- Perform 5-fold cross-validation

### Part 5ï¸âƒ£: Fine-Tune Hyperparameters

- Use GridSearchCV with parameter grid
- Test 36 parameter combinations
- Select best model based on F1-score

### Part 6ï¸âƒ£: Evaluate on Test Set

- Test on 1,845 samples (10%)
- Report accuracy, precision, recall, F1-score
- Analyze confusion matrix
- Visualize results

---

## ğŸ“Š Expected Results

When properly implemented, the model should achieve:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      EXPECTED MODEL PERFORMANCE       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Test Accuracy:   ~84-85%            â•‘
â•‘  Test Precision:  ~85%               â•‘
â•‘  Test Recall:     ~98-99%            â•‘
â•‘  Test F1-Score:   ~91%               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Key Metrics Explained

| Metric | Interpretation |
|--------|----------------|
| **Accuracy** | Overall correctness of predictions |
| **Precision** | Of predicted recommendations, how many correct |
| **Recall** | Of actual recommendations, how many found |
| **F1-Score** | Harmonic mean (balanced precision/recall) |

---

## ğŸ§  NLP Techniques

This project demonstrates several NLP preprocessing techniques:

1. **ğŸ”¤ Tokenization** - Split text into words/tokens
2. **ğŸš« Stop Word Removal** - Filter common words (the, a, and)
3. **2ï¸âƒ£ N-gram Creation** - Extract word pairs and single words
4. **ğŸ“ˆ TF-IDF Vectorization** - Convert text to numerical features
5. **ğŸ˜Š Sentiment Analysis** - Count positive/negative words
6. **ğŸ“ Feature Scaling** - Normalize numerical values

---

## ğŸ—ï¸ Pipeline Architecture

```
Raw Data (18,442 reviews)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FEATURE ENGINEERING         â”‚
â”‚  â€¢ Text features             â”‚
â”‚  â€¢ Sentiment indicators      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PREPROCESSING               â”‚
â”‚  â€¢ StandardScaler (numeric)  â”‚
â”‚  â€¢ OneHotEncoder (category)  â”‚
â”‚  â€¢ TfidfVectorizer (text)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FEATURE MATRIX              â”‚
â”‚  (~162 total features)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RANDOM FOREST CLASSIFIER    â”‚
â”‚  (200 decision trees)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ğŸ¯ Binary Prediction (0 or 1)
```

---

## ğŸ“– How to Run

### Step 1: Navigate to Project

```bash
cd dsnd-pipelines-project
```

### Step 2: Activate Environment

```bash
source venv/bin/activate  # macOS/Linux
# or
venv\Scripts\activate     # Windows
```

### Step 3: Start Jupyter

```bash
jupyter notebook
```

### Step 4: Open Notebook

Click on **`starter/starter.ipynb`**

### Step 5: Run Cells Sequentially

Execute each cell from top to bottom. Each cell builds on previous results.

---

## ğŸ§ª Testing

The project includes integrated testing:

- âœ… **Train-Test Split**: 90-10 split prevents data leakage
- âœ… **Cross-Validation**: 5-fold CV validates generalization
- âœ… **Multiple Metrics**: Accuracy, precision, recall, F1-score
- âœ… **Confusion Matrix**: Detailed error analysis
- âœ… **Visualizations**: Plots for results interpretation

**No external test suite required** - evaluation is built into the notebook.

---

## ğŸ› Troubleshooting

### Issue: ModuleNotFoundError: No module named 'spacy'

**Solution:**
```bash
pip install spacy
python -m spacy download en_core_web_sm
```

### Issue: Data file not found

**Solution:**
Ensure you're running the notebook from `starter/` folder or adjust the path:
```python
df = pd.read_csv('data/reviews.csv')  # From starter/ folder
```

### Issue: GridSearchCV taking too long

**Solution:**
- Reduce CV folds: `cv=3` instead of `cv=5`
- Reduce parameter combinations
- Use smaller dataset for testing

### Issue: Out of memory error

**Solution:**
```python
# Reduce features in TfidfVectorizer
TfidfVectorizer(max_features=50)  # Reduce from 100

# Reduce categories in OneHotEncoder
OneHotEncoder(max_categories=20)  # Reduce from 50
```

---

## âœ¨ Features & Highlights

- âœ… **Complete pipeline** from data to predictions
- âœ… **Handles mixed data types** (numerical, categorical, text)
- âœ… **Proper train/test split** with no data leakage
- âœ… **Cross-validation** for robust evaluation
- âœ… **Hyperparameter tuning** with GridSearchCV
- âœ… **NLP preprocessing** with multiple techniques
- âœ… **Multiple evaluation metrics** for comprehensive assessment
- âœ… **Well-documented code** with docstrings
- âœ… **Professional visualizations** of results

---

## ğŸš€ Advanced Usage

### Save Trained Model

```python
import joblib

# Save the pipeline
joblib.dump(best_pipeline, 'recommendation_model.pkl')

# Load the pipeline
loaded_pipeline = joblib.load('recommendation_model.pkl')
```

### Make Batch Predictions

```python
# On new data
predictions = best_pipeline.predict(X_new)
probabilities = best_pipeline.predict_proba(X_new)

# Create results dataframe
results = pd.DataFrame({
    'prediction': predictions,
    'probability': probabilities[:, 1]
})
```

### Extract Feature Importance

```python
# Get feature importance from Random Forest
importance = best_pipeline.named_steps['classifier'].feature_importances_

# Display top features
top_features = pd.Series(importance).nlargest(10)
print(top_features)
```

---

## ğŸ“š Learning Resources

| Resource | Link |
|----------|------|
| **scikit-learn Docs** | https://scikit-learn.org/stable/ |
| **pandas Docs** | https://pandas.pydata.org/docs/ |
| **Jupyter Guide** | https://jupyter.readthedocs.io/ |
| **spaCy Tutorial** | https://spacy.io/usage |
| **TF-IDF Explanation** | https://en.wikipedia.org/wiki/Tf%E2%80%93idf |

---

## âš–ï¸ License

This project is licensed under the **MIT License** - see [LICENSE.txt](LICENSE.txt) for details.

### You are free to:
- âœ… Use this project
- âœ… Modify the code
- âœ… Distribute copies
- âœ… Use it commercially

### Conditions:
- âš ï¸ Include license and copyright notice

---

## ğŸ› ï¸ Built With

| Technology | Purpose |
|-----------|---------|
| ğŸ **Python 3.7+** | Programming language |
| ğŸ¤– **scikit-learn** | ML algorithms & preprocessing |
| ğŸ“Š **pandas** | Data manipulation |
| ğŸ”¢ **NumPy** | Numerical computing |
| ğŸ§  **spaCy** | NLP text processing |
| ğŸ““ **Jupyter** | Interactive notebooks |
| ğŸ“ˆ **Matplotlib** | Data visualization |
| ğŸ¨ **Seaborn** | Statistical plots |

---

## ğŸ‘¥ Contributing

This is an **educational project** for Udacity's Data Science Nanodegree.

For improvements or bug reports, please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## ğŸ“ Support

### Getting Help

1. **Check the starter/README.md** for student instructions
2. **Read code comments** in starter.ipynb
3. **Review the rubric** for requirements
4. **Google the error** with library name
5. **Check documentation** of relevant libraries

### Common Questions

**Q: Why am I getting different results?**
A: Random state should be 27 in train_test_split and RandomForest.

**Q: What if my accuracy is too low?**
A: Check data preprocessing, feature engineering, and model parameters.

**Q: Can I use a different classifier?**
A: Yes! Try XGBoost, GradientBoosting, or SVM for comparison.

---

## ğŸ“ Educational Value

This project teaches:
- ğŸ”„ End-to-end ML pipeline development
- ğŸ“ Data preprocessing and feature engineering
- ğŸ§  NLP text processing techniques
- ğŸ¯ Model training and evaluation
- âš™ï¸ Hyperparameter optimization
- ğŸ“Š Cross-validation and metrics
- ğŸ“ˆ Results visualization and interpretation

---

## ğŸ“ˆ Performance Summary

| Component | Status | Details |
|-----------|--------|---------|
| **Data Loading** | âœ… Complete | 18,442 reviews loaded |
| **Preprocessing** | âœ… Complete | All 3 data types handled |
| **Feature Engineering** | âœ… Complete | 8 new features created |
| **Model Pipeline** | âœ… Complete | Integrated preprocessing + classifier |
| **Training** | âœ… Complete | 16,597 samples trained |
| **Evaluation** | âœ… Complete | Multiple metrics reported |
| **Tuning** | âœ… Complete | GridSearchCV with 36 combos |
| **Testing** | âœ… Complete | 1,845 samples evaluated |

---

## ğŸ‰ Next Steps

After completing this project:

1. ğŸš€ Deploy the model as an API
2. ğŸ“Š Build a dashboard for predictions
3. ğŸ“ˆ Try advanced ML techniques
4. ğŸ”„ Implement continuous monitoring
5. ğŸ’¡ Apply to your own datasets

---

## ğŸ“ Citation

If you use this project, please cite:

```bibtex
@project{StyleSenseRecommendation,
  title={Fashion Forward Forecasting: StyleSense Product Recommendation Pipeline},
  author={Udacity Data Science Team},
  year={2024},
  url={https://github.com/udacity/dsnd-pipelines-project}
}
```

---

**Made with â¤ï¸ for aspiring data scientists**

[![GitHub](https://img.shields.io/badge/GitHub-Repository-black.svg)](https://github.com/udacity/dsnd-pipelines-project)
[![Udacity](https://img.shields.io/badge/Udacity-Data%20Science%20ND-blue.svg)](https://www.udacity.com/)

**Last Updated**: 2024 | **Status**: Production Ready âœ¨
